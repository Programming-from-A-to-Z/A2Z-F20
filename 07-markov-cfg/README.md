# Session 7 - Markov Chains and Grammars

## Markov Chains

- ğŸ“• [Markov Chains](http://setosa.io/blog/2014/07/26/markov-chains/) by Victor Powell and Lewis Lehe
- ğŸš¨ [Markov Chain video tutorial Part 1](https://youtu.be/eGFJ8vugIWA)
- ğŸ¿ [Markov Chain video tutorial Part 2](https://youtu.be/9r8CmofnbAQ)
- ğŸ’» [Markov Chain p5.js code examples](https://editor.p5js.org/a2zitp/collections/WEXEPRHuE)
- ğŸ“š [N-Grams and Markov Chains by Allison Parrish](http://www.decontextualize.com/teaching/rwet/n-grams-and-markov-chains/)
- ğŸ“š [2016 Markov Chains notes from A2Z](https://shiffman.net/a2z/markov/)
- ğŸ“š [N-Grams and Markov Chains by Allison Parrish](http://www.decontextualize.com/teaching/rwet/n-grams-and-markov-chains/)

### Markov Project References

- ğŸ¨ [ITP Course Generator by Allison Parrish](http://static.decontextualize.com/toys/next_semester)
- ğŸ¨ [WebTrigrams by Chris Harrison](http://www.chrisharrison.net/index.php/Visualizations/WebTrigrams)
- ğŸ“ˆ [Google N-Gram Viewer](https://books.google.com/ngrams), [google blog post about n-grams](http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html)
- ğŸ¨ [King James Programming](http://kingjamesprogramming.tumblr.com/)
- ğŸ¨ [Gnoetry](http://www.beardofbees.com/gnoetry.html)

## Context-Free Grammar

- ğŸš¨ [CFG with Tracery](https://youtu.be/C3EwsSNJeOE?list=PLRqwX-V7Uu6YrbSJBg32eTzUU50E2B8Ch), [Tracery by Kate Compton](http://tracery.io/)
- ğŸ¿ [CFG with RiTa](https://youtu.be/VaAoIaZ3YKs)
- ğŸ¿ [CFG "from scratch" with p5.js](https://youtu.be/8Z9FRiW2Jlc)
- ğŸ’» [CFG p5.js code examples](https://editor.p5js.org/a2zitp/collections/5IFiJuQZa)
- ğŸ“š[Context-Free Grammars by Allison Parrish](http://www.decontextualize.com/teaching/rwet/recursion-and-context-free-grammars/)
- ğŸ“š [2016 Notes on Context-Free Grammar](http://shiffman.net/a2z/cfg)

### CFG Project References

- ğŸ¨ [GenGen by Darius Kazemi](http://tinysubversions.com/gengen/)
- ğŸ¤– [Art Assignment Bot](https://twitter.com/artassignbot?lang=en)

## Reading

- ğŸ“• [What Can Machine Learning Teach Us About Ourselves?](https://medium.com/processing-foundation/what-can-machine-learning-teach-us-about-ourselves-65b268431890), Interview with Emily Martinez, ml5.js Fellow 2020
- ğŸ“• [The Subtext of a Black Corpus](https://medium.com/ml5js/the-subtext-of-a-black-corpus-4440de02eb32), In conversation with ITP research fellows Nikita Huggins & Ayodamola Okunseinde by Ashley Lewis

## Assignment

It is not required to write any new code for this assignment. You are welcome to run one or more of the provided examples with your own data. You can document the results in a blog post (or link to a web page where the text is generated). I'll include some other ideas below in case you are feeling ambitious.

### Markov Chain

Use one of the [existing examples](https://editor.p5js.org/a2zitp/collections/WEXEPRHuE) to generate text with your own input data. Experiment with the "order" and "maximum" length variables. Try mixing multiple texts. Copy paste your favorite outputs from the browser and document in a blog post.

Some additional ideas:

- Design a webpage to display the output of a markov generator a la [Allison Parrish's ITP course creator](http://static.decontextualize.com/toys/next_semester).
- Create a bot that generates its output based on a markov chain.
- Use a markov chain on something other than text. Record your own sequence of daily habits. Try musical notes. Could colors or shapes be generated with a markov chain? What else? You can find examples for [musical markov chains](https://luisaph.github.io/the-code-of-music-2018/#Markov) from Luisa Pereira's [Code of Music materials](https://luisaph.github.io/the-code-of-music-2018/).
- Visualize n-gram frequencies.

### Context-Free Grammar

Invent your own grammar and generate text. Feel free to use [Tracery](http://tracery.io/) or even try Allison Parrish's new [Seaduck](https://github.com/aparrish/seaduck). [Here are all the p5.js examples](https://editor.p5js.org/a2zitp/collections/5IFiJuQZa).

Getting results from a context-free-grammar can be tricky. Short and sweet, highly structured ideas tend to work well. For example.

- A coffee drink order generator.
- An apology generator.
- An ITP project idea generator.
- A knock knock joke generator.

## Add your assignment below via Pull Request

_(Please note you are welcome to post under a pseudonym and/or password protect your published assignment. Here is some [helpful information on privacy options for an NYU blog](https://nyu.service-now.com/sp?id=kb_article&sysparm_article=KB0012245&sys_kb_id=b2ddc9da004aa1002a5d036a271e5f70&spa=1). Finally, if you prefer not to post your assignment at all here, you may email the submission.)_

## Emoji Key for Video Tutorials, Readings, and more

- ğŸš¨ Watch this video tutorial! (this is technical info needed for the examples). Of course if you alreaddy know this material, you can skip.
- ğŸ”¢ This is found in a group, maybe pick just one to check out!
- ğŸ¿ Additional video if you have a particular interest and want to do a deeper dive.
- ğŸ“• Required reading! Let's make sure we all have read this.
- ğŸ“š Optional additional reading for a deeper dive.
- ğŸ’» Code examples here!
- ğŸ“ˆ Class presentation slides
- ğŸ”— Extra reference material / link
